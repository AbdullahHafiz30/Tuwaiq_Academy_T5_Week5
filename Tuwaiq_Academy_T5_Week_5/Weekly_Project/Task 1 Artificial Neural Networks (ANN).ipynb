{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda1ba95",
   "metadata": {},
   "source": [
    "# Exam on Artificial Neural Networks (ANN)\n",
    "\n",
    "Welcome the Artificial Neural Networks (ANN) practical exam. In this exam, you will work on a classification task to predict the outcome of incidents involving buses. You are provided with a dataset that records breakdowns and delays in bus operations. Your task is to build, train, and evaluate an ANN model.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "### **Dataset:**\n",
    "* Just run the command under the `Load Data` section to get the data downloaded and unzipped or you can access it [here](https://drive.google.com/file/d/1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-/view?usp=sharing)\n",
    "\n",
    "### **Dataset Name:** Bus Breakdown and Delays\n",
    "\n",
    "### **Description:**  \n",
    "The dataset contains records of incidents involving buses that were either running late or experienced a breakdown. Your task is to predict whether the bus was delayed or had a breakdown based on the features provided.\n",
    "\n",
    "### **Features:**\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- `School_Year`\n",
    "- `Busbreakdown_ID`\n",
    "- `Run_Type`\n",
    "- `Bus_No`\n",
    "- `Route_Number`\n",
    "- `Reason`\n",
    "- `Schools_Serviced`\n",
    "- `Occurred_On`\n",
    "- `Created_On`\n",
    "- `Boro`\n",
    "- `Bus_Company_Name`\n",
    "- `How_Long_Delayed`\n",
    "- `Number_Of_Students_On_The_Bus`\n",
    "- `Has_Contractor_Notified_Schools`\n",
    "- `Has_Contractor_Notified_Parents`\n",
    "- `Have_You_Alerted_OPT`\n",
    "- `Informed_On`\n",
    "- `Incident_Number`\n",
    "- `Last_Updated_On`\n",
    "- `Breakdown_or_Running_Late` (Target Column)\n",
    "- `School_Age_or_PreK`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b014b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ad02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gdown) (3.15.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abo_o\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abo_O\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gdown\\__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-\n",
      "To: C:\\Users\\abo_O\\AppData\\Local\\Programs\\Microsoft VS Code\\Bus_Breakdown_and_Delays.csv\n",
      "\n",
      "  0%|          | 0.00/34.4M [00:00<?, ?B/s]\n",
      "  2%|▏         | 524k/34.4M [00:00<00:47, 712kB/s]\n",
      "  3%|▎         | 1.05M/34.4M [00:01<00:30, 1.09MB/s]\n",
      "  5%|▍         | 1.57M/34.4M [00:01<00:23, 1.39MB/s]\n",
      "  6%|▌         | 2.10M/34.4M [00:01<00:21, 1.52MB/s]\n",
      "  8%|▊         | 2.62M/34.4M [00:01<00:20, 1.54MB/s]\n",
      "  9%|▉         | 3.15M/34.4M [00:02<00:21, 1.44MB/s]\n",
      " 11%|█         | 3.67M/34.4M [00:02<00:19, 1.59MB/s]\n",
      " 12%|█▏        | 4.19M/34.4M [00:02<00:18, 1.68MB/s]\n",
      " 14%|█▎        | 4.72M/34.4M [00:03<00:16, 1.82MB/s]\n",
      " 15%|█▌        | 5.24M/34.4M [00:03<00:15, 1.91MB/s]\n",
      " 17%|█▋        | 5.77M/34.4M [00:03<00:16, 1.74MB/s]\n",
      " 18%|█▊        | 6.29M/34.4M [00:03<00:15, 1.83MB/s]\n",
      " 20%|█▉        | 6.82M/34.4M [00:04<00:15, 1.79MB/s]\n",
      " 21%|██▏       | 7.34M/34.4M [00:04<00:16, 1.66MB/s]\n",
      " 23%|██▎       | 7.86M/34.4M [00:05<00:16, 1.58MB/s]\n",
      " 24%|██▍       | 8.39M/34.4M [00:05<00:15, 1.66MB/s]\n",
      " 26%|██▌       | 8.91M/34.4M [00:05<00:15, 1.62MB/s]\n",
      " 27%|██▋       | 9.44M/34.4M [00:05<00:15, 1.64MB/s]\n",
      " 29%|██▉       | 9.96M/34.4M [00:06<00:16, 1.49MB/s]\n",
      " 30%|███       | 10.5M/34.4M [00:06<00:15, 1.55MB/s]\n",
      " 32%|███▏      | 11.0M/34.4M [00:07<00:15, 1.51MB/s]\n",
      " 34%|███▎      | 11.5M/34.4M [00:07<00:15, 1.50MB/s]\n",
      " 35%|███▌      | 12.1M/34.4M [00:07<00:13, 1.61MB/s]\n",
      " 37%|███▋      | 12.6M/34.4M [00:07<00:12, 1.71MB/s]\n",
      " 38%|███▊      | 13.1M/34.4M [00:08<00:12, 1.69MB/s]\n",
      " 40%|███▉      | 13.6M/34.4M [00:08<00:11, 1.75MB/s]\n",
      " 41%|████      | 14.2M/34.4M [00:08<00:11, 1.73MB/s]\n",
      " 43%|████▎     | 14.7M/34.4M [00:09<00:11, 1.75MB/s]\n",
      " 44%|████▍     | 15.2M/34.4M [00:09<00:10, 1.86MB/s]\n",
      " 46%|████▌     | 15.7M/34.4M [00:09<00:11, 1.58MB/s]\n",
      " 47%|████▋     | 16.3M/34.4M [00:10<00:11, 1.55MB/s]\n",
      " 49%|████▊     | 16.8M/34.4M [00:10<00:10, 1.74MB/s]\n",
      " 50%|█████     | 17.3M/34.4M [00:10<00:09, 1.79MB/s]\n",
      " 52%|█████▏    | 17.8M/34.4M [00:11<00:10, 1.62MB/s]\n",
      " 53%|█████▎    | 18.4M/34.4M [00:11<00:09, 1.65MB/s]\n",
      " 55%|█████▍    | 18.9M/34.4M [00:11<00:09, 1.66MB/s]\n",
      " 56%|█████▋    | 19.4M/34.4M [00:11<00:08, 1.73MB/s]\n",
      " 58%|█████▊    | 19.9M/34.4M [00:12<00:08, 1.63MB/s]\n",
      " 59%|█████▉    | 20.4M/34.4M [00:12<00:08, 1.56MB/s]\n",
      " 61%|██████    | 21.0M/34.4M [00:12<00:08, 1.57MB/s]\n",
      " 62%|██████▏   | 21.5M/34.4M [00:13<00:07, 1.69MB/s]\n",
      " 64%|██████▍   | 22.0M/34.4M [00:13<00:06, 1.82MB/s]\n",
      " 65%|██████▌   | 22.5M/34.4M [00:13<00:06, 1.78MB/s]\n",
      " 67%|██████▋   | 23.1M/34.4M [00:14<00:05, 1.90MB/s]\n",
      " 69%|██████▊   | 23.6M/34.4M [00:14<00:05, 1.93MB/s]\n",
      " 70%|███████   | 24.1M/34.4M [00:14<00:05, 1.75MB/s]\n",
      " 72%|███████▏  | 24.6M/34.4M [00:15<00:05, 1.65MB/s]\n",
      " 73%|███████▎  | 25.2M/34.4M [00:15<00:05, 1.74MB/s]\n",
      " 75%|███████▍  | 25.7M/34.4M [00:15<00:05, 1.61MB/s]\n",
      " 76%|███████▌  | 26.2M/34.4M [00:15<00:04, 1.65MB/s]\n",
      " 78%|███████▊  | 26.7M/34.4M [00:16<00:04, 1.70MB/s]\n",
      " 79%|███████▉  | 27.3M/34.4M [00:16<00:04, 1.71MB/s]\n",
      " 81%|████████  | 27.8M/34.4M [00:16<00:03, 1.68MB/s]\n",
      " 82%|████████▏ | 28.3M/34.4M [00:17<00:03, 1.58MB/s]\n",
      " 84%|████████▍ | 28.8M/34.4M [00:17<00:03, 1.59MB/s]\n",
      " 85%|████████▌ | 29.4M/34.4M [00:17<00:03, 1.59MB/s]\n",
      " 87%|████████▋ | 29.9M/34.4M [00:18<00:02, 1.64MB/s]\n",
      " 88%|████████▊ | 30.4M/34.4M [00:18<00:02, 1.60MB/s]\n",
      " 90%|████████▉ | 30.9M/34.4M [00:18<00:02, 1.63MB/s]\n",
      " 91%|█████████▏| 31.5M/34.4M [00:19<00:01, 1.70MB/s]\n",
      " 93%|█████████▎| 32.0M/34.4M [00:19<00:01, 1.37MB/s]\n",
      " 94%|█████████▍| 32.5M/34.4M [00:19<00:01, 1.49MB/s]\n",
      " 96%|█████████▌| 33.0M/34.4M [00:20<00:00, 1.54MB/s]\n",
      " 97%|█████████▋| 33.6M/34.4M [00:20<00:00, 1.58MB/s]\n",
      " 99%|█████████▉| 34.1M/34.4M [00:20<00:00, 1.67MB/s]\n",
      "100%|██████████| 34.4M/34.4M [00:21<00:00, 1.64MB/s]\n",
      "100%|██████████| 34.4M/34.4M [00:21<00:00, 1.63MB/s]\n"
     ]
    }
   ],
   "source": [
    "#https://drive.google.com/file/d/1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-/view?usp=sharing\n",
    "!pip install gdown\n",
    "!gdown --id 1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39620c",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62381953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ccd4e2",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "This could include:\n",
    "* **Inspect the dataset**\n",
    "\n",
    "* **Dataset structure**\n",
    "\n",
    "* **Summary statistics**\n",
    "\n",
    "* **Check for missing values**\n",
    "\n",
    "* **Distribution of features**\n",
    "\n",
    "* **Categorical feature analysis**\n",
    "\n",
    "* **Correlation matrix**\n",
    "\n",
    "* **Outlier detection**\n",
    "\n",
    "And add more as needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b800b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a559e40",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This could include:\n",
    "\n",
    "* **Handle Missing Values**\n",
    "    * Impute missing values or drop them.\n",
    "\n",
    "* **Encode Categorical Variables**\n",
    "    * One-hot encoding\n",
    "    * Label encoding\n",
    "\n",
    "* **Scale and Normalize Data**\n",
    "    * Standardization (Z-score)\n",
    "    * Min-Max scaling\n",
    "\n",
    "* **Feature Engineering**\n",
    "    * Create new features\n",
    "    * Feature selection\n",
    "\n",
    "* **Handle Imbalanced Data**\n",
    "    * Oversampling\n",
    "    * Undersampling\n",
    "\n",
    "* **Handle Outliers**\n",
    "    * Remove outliers\n",
    "    * Transform outliers\n",
    "\n",
    "* **Remove Duplicates**\n",
    "    * Remove redundant or duplicate data\n",
    "\n",
    "\n",
    "And add more as needed!\n",
    "\n",
    "Please treat these as suggestions. Feel free to use your judgment for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6867a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc887660",
   "metadata": {},
   "source": [
    "## Split the Dataset\n",
    "Next, split the dataset into training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bbfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7119b7d7",
   "metadata": {},
   "source": [
    "## Building the ANN Model\n",
    "In this section, define the architecture of the ANN by specifying the number of layers, neurons, and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8532b3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac5e52e1",
   "metadata": {},
   "source": [
    "## Compile the Model\n",
    "Compile the ANN model by defining the optimizer, loss function, and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab363be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9a72223",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Train the ANN model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43fedab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20ce9661",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Evaluate the performance of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73167afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08e9bc87",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "Use the trained model to make predictions on new or unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fa394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94942463",
   "metadata": {},
   "source": [
    "## Model Performance Visualization\n",
    "Visualize the performance metrics such as accuracy and loss over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1955952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d32965f",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "Save the trained model for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1f00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ebe9b8d",
   "metadata": {},
   "source": [
    "## Project Questions:\n",
    "\n",
    "1. **Data Preprocessing**: Explain why you chose your specific data preprocessing techniques (e.g., normalization, encoding). How did these techniques help prepare the data for training the model?\n",
    "2. **Model Architecture**: Describe the reasoning behind your model’s architecture (e.g., the number of layers, type of layers, number of neurons, and activation functions). Why did you believe this architecture was appropriate for the problem at hand?\n",
    "3. **Training Process**: Discuss why you chose your batch size, number of epochs, and optimizer. How did these choices affect the training process? Did you experiment with different values, and what were the outcomes?\n",
    "4. **Loss Function and Metrics**: Why did you choose the specific loss function and evaluation metrics? How do they align with the objective of the task (e.g., regression vs classification)?\n",
    "5. **Regularization Techniques**: If you used regularization techniques such as dropout or weight decay, explain why you implemented them and how they influenced the model's performance.\n",
    "6. **Model Evaluation**: Justify your approach to evaluating the model. Why did you choose the specific performance metrics, and how do they reflect the model's success in solving the task?\n",
    "7. **Model Tuning (If Done)**: Describe any tuning you performed (e.g., hyperparameter tuning) and why you felt it was necessary. How did these adjustments improve model performance?\n",
    "8. **Overfitting and Underfitting**: Analyze whether the model encountered any overfitting or underfitting during training. What strategies could you implement to mitigate these issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f524a61",
   "metadata": {},
   "source": [
    "### Answer Here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
